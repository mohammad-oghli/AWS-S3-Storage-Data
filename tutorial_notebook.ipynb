{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Storage Class from S3 Module\n",
    "First you should import **StorageS3** into your project source code \n",
    "\n",
    "`from S3 import StorageS3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating New AWS S3 Storage Object\n",
    "You can create new object of S3 bucket using `name` attribute of your S3 on AWS\n",
    "\n",
    "When you create S3 storage object the default region will be `us-east-1`\n",
    "\n",
    "If your S3 bucket in different region you will get error message when you read file in it indicating that you need to set the default region for all your objects of the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default AWS Region has been set up\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (IllegalLocationConstraintException) when calling the GetObject operation: The eu-north-1 location constraint is incompatible for the region specific endpoint this request was sent to.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mS3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StorageS3\n\u001b[1;32m      3\u001b[0m s3_store1 \u001b[38;5;241m=\u001b[39m StorageS3(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3-demo-store1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m acpc_datasest \u001b[38;5;241m=\u001b[39m \u001b[43ms3_store1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/acpc_result_5yrs.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AWS-S3-Storage/S3.py:62\u001b[0m, in \u001b[0;36mStorageS3.read_file\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Read file in aws s3 storage.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        bytes: Object content of the file in byte format.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     object_content \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m object_content\n",
      "File \u001b[0;32m~/PycharmProjects/AWS-S3-Storage/venv/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AWS-S3-Storage/venv/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (IllegalLocationConstraintException) when calling the GetObject operation: The eu-north-1 location constraint is incompatible for the region specific endpoint this request was sent to."
     ]
    }
   ],
   "source": [
    "from S3 import StorageS3\n",
    "\n",
    "s3_store1 = StorageS3(name='s3-demo-store1')\n",
    "acpc_datasest = s3_store1.read_file(file_path='dataset/acpc_result_5yrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only need to set the default region paramater when you create object from S3 Storage Class using `default_region` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default AWS Region has been set up\n"
     ]
    }
   ],
   "source": [
    "from S3 import StorageS3\n",
    "\n",
    "# Set the default region to eu-north-1  \n",
    "s3_store1 = StorageS3(name='s3-demo-store1', default_region='eu-north-1')\n",
    "acpc_dataset = s3_store1.read_file(file_path='dataset/acpc_result_5yrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Directories and Files in AWS S3 Storage\n",
    "You can list all directories and files keys in S3 storage object using `list_content` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data-analytics-example/',\n",
       " 'data-analytics-example/notebook/',\n",
       " 'data-analytics-example/notebook/acpc_analytics.ipynb',\n",
       " 'data-analytics-example/plots/',\n",
       " 'data-analytics-example/plots/Top_countries_pie.png',\n",
       " 'data-analytics-example/plots/top_countries_bar.png',\n",
       " 'dataset/',\n",
       " 'dataset/acpc_result_5yrs.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_store1.list_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read File from AWS S3 Storage\n",
    "you can read specific file in S3 storage object using `read_file` method by setting `file_path` attribute for the location of file in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Institution</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Applied Science Private University</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German University in Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cairo University - Faculty of Computers and Ar...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ain Shams University - Faculty of Computer and...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Higher Institute for Applied Sciences and Tech...</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cairo University - Faculty of Computers and Ar...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Syrian Virtual University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Higher Institute for Applied Sciences and Tech...</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arab Academy for Science,Technology and Mariti...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assiut University</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Arab Academy for Science,Technology and Mariti...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Higher Institute for Applied Sciences and Tech...</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Al-Baath University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ain Shams University - Faculty of Computer and...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Damascus University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Damascus University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ain Shams University - Faculty of Computer and...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>German University in Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>German University in Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New York University Abu Dhabi</td>\n",
       "      <td>UAE</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Princess Sumaya University for Technology</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>German University in Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Arab Academy for Science, Technology and Marit...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Assiut University</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ain Shams University - Faculty of Computer and...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tishreen University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ain Shams University - Faculty of Computer and...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>American University of Beirut</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Damascus University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>German University in Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Arab Academy for Science, Technology and Marit...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Damascus University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Arab Academy for Science, Technology and Marit...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ain Shams University - Faculty of Computer and...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Damascus University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Alexandria University - Faculty of Engineering</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Syrian Virtual University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Higher Institute for Applied Sciences and Tech...</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Al-Azhar University</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Damascus University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Princess Sumaya University for Technology</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Arab Academy for Science, Technology and Marit...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Arab Academy for Science, Technology and Marit...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Princess Sumaya University for Technology</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Arab Academy for Science, Technology and Marit...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ain Shams University - Faculty of Computer and...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ain Shams University - Faculty of Computer and...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Syrian Virtual University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Damascus University</td>\n",
       "      <td>Syria</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Arab Academy for Science, Technology and Marit...</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Institution  Country  Year  Place\n",
       "0                  Applied Science Private University   Jordan  2023      1\n",
       "1                          German University in Cairo    Egypt  2023      2\n",
       "2   Cairo University - Faculty of Computers and Ar...    Egypt  2023      3\n",
       "3   Ain Shams University - Faculty of Computer and...    Egypt  2023      4\n",
       "4   Higher Institute for Applied Sciences and Tech...    Syria  2023      5\n",
       "5   Cairo University - Faculty of Computers and Ar...    Egypt  2023      6\n",
       "6                           Syrian Virtual University    Syria  2023      7\n",
       "7   Higher Institute for Applied Sciences and Tech...    Syria  2023      8\n",
       "8   Arab Academy for Science,Technology and Mariti...    Egypt  2023      9\n",
       "9                                   Assiut University    Egypt  2023     10\n",
       "10  Arab Academy for Science,Technology and Mariti...    Egypt  2022      1\n",
       "11  Higher Institute for Applied Sciences and Tech...    Syria  2022      2\n",
       "12                                Al-Baath University    Syria  2022      3\n",
       "13  Ain Shams University - Faculty of Computer and...    Egypt  2022      4\n",
       "14                                Damascus University    Syria  2022      5\n",
       "15                                Damascus University    Syria  2022      6\n",
       "16  Ain Shams University - Faculty of Computer and...    Egypt  2022      7\n",
       "17                         German University in Cairo    Egypt  2022      8\n",
       "18                         German University in Cairo    Egypt  2022      9\n",
       "19                      New York University Abu Dhabi      UAE  2022     10\n",
       "20          Princess Sumaya University for Technology   Jordan  2021      1\n",
       "21                         German University in Cairo    Egypt  2021      2\n",
       "22  Arab Academy for Science, Technology and Marit...    Egypt  2021      3\n",
       "23                                  Assiut University    Egypt  2021      4\n",
       "24  Ain Shams University - Faculty of Computer and...    Egypt  2021      5\n",
       "25                                Tishreen University    Syria  2021      6\n",
       "26  Ain Shams University - Faculty of Computer and...    Egypt  2021      7\n",
       "27                      American University of Beirut  Lebanon  2021      8\n",
       "28                                Damascus University    Syria  2021      9\n",
       "29                         German University in Cairo    Egypt  2021     10\n",
       "30  Arab Academy for Science, Technology and Marit...    Egypt  2020      1\n",
       "31                                Damascus University    Syria  2020      2\n",
       "32  Arab Academy for Science, Technology and Marit...    Egypt  2020      3\n",
       "33  Ain Shams University - Faculty of Computer and...    Egypt  2020      4\n",
       "34                                Damascus University    Syria  2020      5\n",
       "35     Alexandria University - Faculty of Engineering    Egypt  2020      6\n",
       "36                          Syrian Virtual University    Syria  2020      7\n",
       "37  Higher Institute for Applied Sciences and Tech...    Syria  2020      8\n",
       "38                                Al-Azhar University    Egypt  2020      9\n",
       "39                                Damascus University    Syria  2020     10\n",
       "40          Princess Sumaya University for Technology   Jordan  2019      1\n",
       "41  Arab Academy for Science, Technology and Marit...    Egypt  2019      2\n",
       "42  Arab Academy for Science, Technology and Marit...    Egypt  2019      3\n",
       "43          Princess Sumaya University for Technology   Jordan  2019      4\n",
       "44  Arab Academy for Science, Technology and Marit...    Egypt  2019      5\n",
       "45  Ain Shams University - Faculty of Computer and...    Egypt  2019      6\n",
       "46  Ain Shams University - Faculty of Computer and...    Egypt  2019      7\n",
       "47                          Syrian Virtual University    Syria  2019      8\n",
       "48                                Damascus University    Syria  2019      9\n",
       "49  Arab Academy for Science, Technology and Marit...    Egypt  2019     10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "acpc_dataset = s3_store1.read_file(file_path='dataset/acpc_result_5yrs.csv')\n",
    "# get the binary response object using IO \n",
    "dataset_obj = io.BytesIO(acpc_dataset)\n",
    "# read the object as csv \n",
    "df = pd.read_csv(dataset_obj)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write File to AWS S3 Storage\n",
    "You can write file to S3 using `write_file` method by setting the `binary_data` attribute of object content and `output_path` attribute with the name of the file you want to save on your S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_msg = \"hello world from boto3 SDK!\"\n",
    "s3_store1.write_file(binary_data=str_msg, output_path='output/s3-demo-file.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you check your S3 bucket you will find that new file created inside `output` directory \n",
    "\n",
    "You can read the file content and check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world from boto3 SDK!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_demo_content = s3_store1.read_file(file_path='output/s3-demo-file.txt')\n",
    "# convert the binary response object to text encoding\n",
    "str_msg = s3_demo_content.decode('UTF-8')\n",
    "str_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy File from AWS S3 Storage\n",
    "You can copy file inside S3 bucket to another directory in same bucket or to another S3 bucket using `copy_file` method by setting `src_file_path` attribute for the source file location you want to copy and `dest_bucket` attribute for the destination S3 bucket to copy the file to it and `dest_file_path` attribute for the new copied file location "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Copy file to same S3 bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied output/s3-demo-file.txt to output2/s3-demo-file.txt\n"
     ]
    }
   ],
   "source": [
    "# Copy file from s3-demo-store1 to another directory \n",
    "source_file_path = 'output/s3-demo-file.txt'\n",
    "destination_bucket = 's3-demo-store1'\n",
    "destination_file_path = 'output2/s3-demo-file.txt'\n",
    "s3_store1.copy_file(src_file_path=source_file_path, dest_bucket=destination_bucket, dest_file_path=destination_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you check your S3 bucket you will find that new copy of the file created inside output2 directory \n",
    "\n",
    "You can check the file by reading it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world from boto3 SDK!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_demo_copy = s3_store1.read_file(file_path='output2/s3-demo-file.txt')\n",
    "# convert the binary response object to text encoding\n",
    "str_msg = s3_demo_copy.decode('UTF-8')\n",
    "str_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Copy file to another S3 bucket\n",
    "\n",
    "    You can copy the file to different S3 content by setting `dest_bucket` attribute to another S3 bucket \n",
    "    \n",
    "    First we need to create new S3 bucket object for the second S3 storage `s3-demo-store2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default region to eu-north-1  \n",
    "s3_store2 = StorageS3(name='s3-demo-store2', default_region='eu-north-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we only need to copy the file to the second S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied output/s3-demo-file.txt to output/s3-demo-file.txt\n"
     ]
    }
   ],
   "source": [
    "# Copy file from s3-demo-store1 to s3-demo-store2\n",
    "source_file_path = 'output/s3-demo-file.txt'\n",
    "# Second S3 bucket\n",
    "destination_bucket = 's3-demo-store2'\n",
    "destination_file_path = 'output/s3-demo-file.txt'\n",
    "s3_store1.copy_file(src_file_path=source_file_path, dest_bucket=destination_bucket, dest_file_path=destination_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file copied to the second S3 bucket inside output directory \n",
    "\n",
    "We can check it using read_file for `s3-demo-store2` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world from boto3 SDK!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_demo_copy = s3_store2.read_file(file_path='output/s3-demo-file.txt')\n",
    "# convert the binary response object to text encoding\n",
    "str_msg = s3_demo_copy.decode('UTF-8')\n",
    "str_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete File from AWS S3 Storage\n",
    "You can delete specific file in S3 bucket using `delete_file` by setting `file_path` attribute of the file location you want to delete\n",
    "\n",
    "We can delete the new copied file `s3-demo-file.txt` inside `s3-demo-store1` bucket at `output2` directory\n",
    "\n",
    "**Note**: Be careful when using `delete_file` to delete sensitive data in you S3 bucket because it will permantely delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_store1.delete_file(file_path='output2/s3-demo-file.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the file should be deleted from `s3-demo-store1` bucket in `output2` directory \n",
    "\n",
    "We can try to read it and it should return error message because the file doesn't exist anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchKey",
     "evalue": "An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s3_demo_copy \u001b[38;5;241m=\u001b[39m \u001b[43ms3_store1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput2/s3-demo-file.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AWS-S3-Storage/S3.py:62\u001b[0m, in \u001b[0;36mStorageS3.read_file\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Read file in aws s3 storage.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        bytes: Object content of the file in byte format.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     object_content \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m object_content\n",
      "File \u001b[0;32m~/PycharmProjects/AWS-S3-Storage/venv/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AWS-S3-Storage/venv/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist."
     ]
    }
   ],
   "source": [
    "s3_demo_copy = s3_store1.read_file(file_path='output2/s3-demo-file.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Directory from AWS S3 Storage\n",
    "You can copy directory with all files inside it in S3 bucket to another directory in same bucket or another S3 bucket using `copy_directory_files` method by setting `src_dir_path` attribute for the source directory location you want to copy and `dest_bucket` attribute for the destination S3 bucket to copy the directory files to it and `dest_dir_path` attribute for the new copied directory location "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example we can copy `plots` direcory in `data-analytics-example` directory from `s3-demo-store1` bucket to `s3-demo-store2` bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied data-analytics-example/plots/ to plots_copy/data-analytics-example/plots/\n",
      "Copied data-analytics-example/plots/Top_countries_pie.png to plots_copy/data-analytics-example/plots/Top_countries_pie.png\n",
      "Copied data-analytics-example/plots/top_countries_bar.png to plots_copy/data-analytics-example/plots/top_countries_bar.png\n"
     ]
    }
   ],
   "source": [
    "source_prefix = 'data-analytics-example/plots/'\n",
    "destination_bucket = 's3-demo-store2'\n",
    "destination_prefix = 'plots_copy/'\n",
    "s3_store1.copy_directory_files(src_dir_path=source_prefix, dest_bucket=destination_bucket, dest_dir_path=destination_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check `s3-demo-store2` you will find the new directory `plots_copy` created and the copied directory `plots` inside it with all the files \n",
    "\n",
    "**Note**: Copying directory will preserve its directories structure in the source directory \n",
    "\n",
    "In this example if you check the `plots_copy` you will find `plots` directory inside `data-analytics-example` directry which is the same structure of the source directory you copy it from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also if you copy specific directory without setting `dest_dir_path` for the new copied directory location \n",
    "\n",
    "It will copy the directory to the root directory of your S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied data-analytics-example/plots/ to data-analytics-example/plots/\n",
      "Copied data-analytics-example/plots/Top_countries_pie.png to data-analytics-example/plots/Top_countries_pie.png\n",
      "Copied data-analytics-example/plots/top_countries_bar.png to data-analytics-example/plots/top_countries_bar.png\n"
     ]
    }
   ],
   "source": [
    "source_prefix = 'data-analytics-example/plots/'\n",
    "destination_bucket = 's3-demo-store2'\n",
    "s3_store1.copy_directory_files(src_dir_path=source_prefix, dest_bucket=destination_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see now that `plots` diretcory with all files in it copied to the root directory of `s3-demo-store2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get File Permission\n",
    "In order to use **get file permission** method you need to enable `ACLs` object Ownership in your S3 bucket\n",
    "\n",
    "You can get the file permission granted access policies of your `ACLs` using `get_file_permission` method by setting `file_path` attribute of the file location you need to check its permission\n",
    "\n",
    "let's first check `s3-demo-file.txt` file access permission inside output directory in `s3-demo-store1` bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Grantee': {'ID': '9c7c1385b234c8caf5ebce52e98f8a305333ca3d9f4421a8548ef5a953156e42',\n",
       "   'Type': 'CanonicalUser'},\n",
       "  'Permission': 'FULL_CONTROL'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_demo_permission = s3_store1.get_file_permission(file_path='output/s3-demo-file.txt')\n",
    "s3_demo_permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the file you have full control over it with **Private** access permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we check `s3-demo-file.txt` file access permission inside output directory in `s3-demo-store2` bucket which we have already granted public `ACLs` access to it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Grantee': {'ID': '9c7c1385b234c8caf5ebce52e98f8a305333ca3d9f4421a8548ef5a953156e42',\n",
       "   'Type': 'CanonicalUser'},\n",
       "  'Permission': 'FULL_CONTROL'},\n",
       " {'Grantee': {'Type': 'Group',\n",
       "   'URI': 'http://acs.amazonaws.com/groups/global/AllUsers'},\n",
       "  'Permission': 'READ'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_demo_permission = s3_store2.get_file_permission(file_path='output/s3-demo-file.txt')\n",
    "s3_demo_permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the file you have full control over it with **Public** Read access permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set File Permission\n",
    "In order to use **set file permission** method you need to enable `ACLs` object Ownership in your S3 bucket\n",
    "\n",
    "You can set your file `ACLs` access permission using `set_file_permission` method by setting `file_path` attribute of the file location you need to set its access permission and `public` attribute of the access permission type\n",
    "\n",
    "**Note**: The default value of `public` attribute is `False` which indicate that it's private access for the specified file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As example if you want to set `s3-demo-file.txt` file access permission inside output directory in `s3-demo-store1` bucket to **Public** Read access permission.\n",
    "\n",
    "First you should edit `Block public access` in your bucket setting and uncheck the following options:\n",
    "\n",
    "* Block public access to buckets and objects granted through new access control lists (ACLs)\n",
    "\n",
    "* Block public access to buckets and objects granted through any access control lists (ACLs) \n",
    "\n",
    "Then you can set the access permission successfully "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Grantee': {'ID': '9c7c1385b234c8caf5ebce52e98f8a305333ca3d9f4421a8548ef5a953156e42',\n",
       "   'Type': 'CanonicalUser'},\n",
       "  'Permission': 'FULL_CONTROL'},\n",
       " {'Grantee': {'Type': 'Group',\n",
       "   'URI': 'http://acs.amazonaws.com/groups/global/AllUsers'},\n",
       "  'Permission': 'READ'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_demo_new_permission = s3_store1.set_file_permission(file_path='output/s3-demo-file.txt', public=True)\n",
    "s3_demo_new_permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great you can confirm now that the access permission for the file is `Public`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can change `s3-demo-file.txt` public access permission inside output directory in `s3-demo-store2` bucket to `Private`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Grantee': {'ID': '9c7c1385b234c8caf5ebce52e98f8a305333ca3d9f4421a8548ef5a953156e42',\n",
       "   'Type': 'CanonicalUser'},\n",
       "  'Permission': 'FULL_CONTROL'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_demo_new_permission = s3_store2.set_file_permission(file_path='output/s3-demo-file.txt', public=False)\n",
    "# the default value of public attribute false so you can run the method using the defalut value\n",
    "# s3_demo_new_permission = s3_store2.set_file_permission(file_path='output/s3-demo-file.txt')\n",
    "s3_demo_new_permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the access permission changed to **Private** for `s3-demo-file.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Directory Permission\n",
    "In order to use **set directory permission** method you need to enable `ACLs` object Ownership in your S3 bucket\n",
    "\n",
    "You can set your directory files `ACLs` access permission using `set_directory_permission` method by setting `dir_path` attribute of the directory location you need to set its files access permission and `public` attribute of the access permission type\n",
    "\n",
    "**Note**: The default value of `public` attribute is `False` which indicate that it's private access for the directory files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example you can set `plots` directory files access permission in `s3-demo-store2` bucket to **Public** Read access permission. \n",
    "\n",
    "First we need to check access permission for one of the plots inside `plots` directory in `s3-demo-store2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Grantee': {'ID': '9c7c1385b234c8caf5ebce52e98f8a305333ca3d9f4421a8548ef5a953156e42',\n",
       "   'Type': 'CanonicalUser'},\n",
       "  'Permission': 'FULL_CONTROL'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_demo_permission = s3_store2.get_file_permission(file_path='data-analytics-example/plots/Top_countries_pie.png')\n",
    "s3_demo_permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has **Private** access permission!\n",
    "\n",
    "After that we will set the access permission for `plots` directory to `Public`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory data-analytics-example/plots/ objects set to public-read\n"
     ]
    }
   ],
   "source": [
    "s3_store2.set_directory_permission(dir_path='data-analytics-example/plots/', public=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to confirm that access permission changed for the `plots` directory files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Grantee': {'ID': '9c7c1385b234c8caf5ebce52e98f8a305333ca3d9f4421a8548ef5a953156e42',\n",
       "   'Type': 'CanonicalUser'},\n",
       "  'Permission': 'FULL_CONTROL'},\n",
       " {'Grantee': {'Type': 'Group',\n",
       "   'URI': 'http://acs.amazonaws.com/groups/global/AllUsers'},\n",
       "  'Permission': 'READ'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_demo_permission = s3_store2.get_file_permission(file_path='data-analytics-example/plots/Top_countries_pie.png')\n",
    "s3_demo_permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome it's **Public** Read access permission now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Docs Info\n",
    "You can get more information about `StorageS3` class attributes and methods using `help` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StorageS3 in module S3:\n",
      "\n",
      "class StorageS3(builtins.object)\n",
      " |  StorageS3(name, default_region='me-central-1')\n",
      " |  \n",
      " |  A class representing aws s3 storage.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      name (str): The Name of the aws s3 bucket.\n",
      " |      default_region (str): The default region for aws s3 bucket.\n",
      " |      recent_def_region (list): A list containing recent default region of s3 objects.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, name, default_region='me-central-1')\n",
      " |      Initializes StorageS3 object.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          name (str): The Name of the aws s3 bucket.\n",
      " |          default_region (str): The default region for aws s3 bucket.\n",
      " |  \n",
      " |  copy_directory_files(self, src_dir_path, dest_bucket, dest_dir_path='')\n",
      " |      Copy Directory files from aws s3 storage.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          src_dir_path (str): The location of the directory to copy in source s3 bucket.\n",
      " |          dest_bucket (str): The destination s3 bucket that will store the copied directory files.\n",
      " |          dest_dir_path (str): The location of copied directory in destination s3 bucket.\n",
      " |  \n",
      " |  copy_file(self, src_file_path, dest_bucket, dest_file_path='')\n",
      " |      Copy file from aws s3 storage.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          src_file_path (str): The location of the file to copy in source s3 bucket.\n",
      " |          dest_bucket (str): The destination s3 bucket that will store the copied file.\n",
      " |          dest_file_path (str): The location of copied file in destination s3 bucket.\n",
      " |  \n",
      " |  delete_file(self, file_path)\n",
      " |      Delete file from aws s3 storage.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          file_path (str): File location in s3 bucket.\n",
      " |  \n",
      " |  get_file_permission(self, file_path)\n",
      " |      Get file access permission policy in aws s3 storage.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          file_path (str): File location in s3 bucket.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: Dict contains access permission policy information of the file.\n",
      " |  \n",
      " |  read_file(self, file_path)\n",
      " |      Read file in aws s3 storage.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          file_path (str): File location in s3 bucket.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bytes: Object content of the file in byte format.\n",
      " |  \n",
      " |  set_directory_permission(self, dir_path, public=False)\n",
      " |  \n",
      " |  set_file_permission(self, file_path, public=False)\n",
      " |      Set file access permission policy in aws s3 storage.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          file_path (str): File location in s3 bucket.\n",
      " |          public (bool): Access permission type of the file which is public or private access permission.\n",
      " |  \n",
      " |  write_file(self, binary_data, output_path)\n",
      " |      Write file in aws s3 storage.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          binary_data (bytes): Data content to write in new file.\n",
      " |          file_path (str): File location in s3 bucket.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  set_default_region(region_name) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  recent_def_region = ['eu-north-1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StorageS3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well you can check specific class method info using `help` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_file in module S3:\n",
      "\n",
      "read_file(self, file_path)\n",
      "    Read file in aws s3 storage.\n",
      "    \n",
      "    Parameters:\n",
      "        file_path (str): File location in s3 bucket.\n",
      "    \n",
      "    Returns:\n",
      "        bytes: Object content of the file in byte format.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StorageS3.read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Author [Mohamad Oghli](https://www.linkedin.com/in/mohammad-oghli/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
